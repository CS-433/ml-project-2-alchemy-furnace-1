INFO: Using device cuda
INFO: Network:
	3 input channels
	2 output channels (classes)
	Transposed conv upscaling
INFO: Creating dataset with 100 examples
INFO: Scanning mask files to determine unique values
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:10,  9.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 603.73it/s]
INFO: Unique mask values: [0, 255]
INFO: Creating dataset with 100 examples
INFO: Scanning mask files to determine unique values
  0%|          | 0/100 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1489.45it/s]
INFO: Unique mask values: [0, 255]
INFO: Creating dataset with 100 examples
INFO: Scanning mask files to determine unique values
  0%|          | 0/100 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 2764.50it/s]
INFO: Unique mask values: [0, 255]
INFO: Creating dataset with 90 examples
INFO: Scanning mask files to determine unique values
  0%|          | 0/90 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 2003.14it/s]
INFO: Unique mask values: [0, 255]
INFO: Creating dataset with 100 examples
INFO: Scanning mask files to determine unique values
  0%|          | 0/100 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1321.94it/s]
INFO: Unique mask values: [0, 255]
INFO: Creating dataset with 50 examples
INFO: Scanning mask files to determine unique values
  0%|          | 0/50 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 1301.47it/s]
INFO: Unique mask values: [0, 255]
/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: awakening (awakening-wyf). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /home/yifwang/ml-project-2-alchemy-furnace-1/wandb/run-20241217_160843-sk1fbhc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-bird-102
wandb: â­ï¸ View project at https://wandb.ai/awakening-wyf/U-Net
wandb: ðŸš€ View run at https://wandb.ai/awakening-wyf/U-Net/runs/sk1fbhc1
INFO: Starting training:
        Epochs:          45
        Batch size:      12
        Learning rate:   0.0003
        Training size:   490
        Validation size: 50
        Checkpoints:     True
        Device:          cuda
        Images scaling:  0.5
        Mixed Precision: False
    
Epoch 1/45:   0%|          | 0/490 [00:00<?, ?img/s]/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 40, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Epoch 1/45:   2%|â–         | 12/490 [00:01<01:13,  6.50img/s]Epoch 1/45:   2%|â–         | 12/490 [00:01<01:13,  6.50img/s, loss (batch)=2.89]Epoch 1/45:   5%|â–         | 24/490 [00:01<01:11,  6.50img/s, loss (batch)=2.14]Epoch 1/45:   5%|â–         | 24/490 [00:01<00:36, 12.85img/s, loss (batch)=2.14]
Traceback (most recent call last):
  File "/home/yifwang/ml-project-2-alchemy-furnace-1/scripts/train.py", line 278, in <module>
    train_model(
  File "/home/yifwang/ml-project-2-alchemy-furnace-1/scripts/train.py", line 151, in train_model
    for batch in train_loader:
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1445, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
AssertionError: Caught AssertionError in DataLoader worker process 2.
Original Traceback (most recent call last):
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yifwang/anaconda3/envs/ada/lib/python3.11/site-packages/torch/utils/data/dataset.py", line 350, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/yifwang/ml-project-2-alchemy-furnace-1/scripts/../utils/data_loading.py", line 98, in __getitem__
    assert len(img_file) == 1, f'Either no image or multiple images found for the ID {name}: {img_file}'
           ^^^^^^^^^^^^^^^^^^
AssertionError: Either no image or multiple images found for the ID satImage_008: []

